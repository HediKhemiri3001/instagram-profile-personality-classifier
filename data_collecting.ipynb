{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2192,"status":"ok","timestamp":1685486510781,"user":{"displayName":"Naim Dali","userId":"15388285116851602609"},"user_tz":-60},"id":"S7XhrOaN83WC","outputId":"15d8e3a0-d89e-419a-d4a5-6bc883301a85"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1685486513180,"user":{"displayName":"Naim Dali","userId":"15388285116851602609"},"user_tz":-60},"id":"HklddntU8v5Y"},"outputs":[],"source":["\n","import cv2\n","import os\n","import pandas as pd\n","import os\n","import cv2\n","import csv\n","import pandas as pd\n","import datetime\n","import json\n","import lzma\n","from sklearn.model_selection import train_test_split\n","\n","\n","root_dir = \"/content/drive/MyDrive/PFA/DATASET/Data/\"\n","\n","\n","# -------------------MP4 to image---------------\n","def convert_mp4_to_image():\n","    # path to the directory containing the user folders conatining the videos\n","    \n","    Users = os.listdir(root_dir)\n","\n","    # loop over all the users in the directory\n","    for user_folder in Users:\n","        path_to_user = root_dir+\"/\"+user_folder\n","        \n","        # loop over files in each directory\n","        for file_name in os.listdir(path_to_user):\n","            if file_name.endswith('.mp4'):\n","                \n","                # read the video file\n","                video = cv2.VideoCapture(os.path.join(path_to_user, file_name))\n","                \n","                # get the first frame of the video\n","                success, image = video.read()\n","\n","                # save the frame as an image file\n","                if success:\n","                    image_path = os.path.join(path_to_user, os.path.splitext(file_name)[0] + '.jpg')\n","                    print(image_path)\n","                    cv2.imwrite(image_path, image)\n","                    os.remove(path=os.path.join(path_to_user, file_name))\n","                else:\n","                    print(f'Failed to extract first frame from {file_name}')\n","\n","                # release the video capture object\n","                video.release()"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1685486515760,"user":{"displayName":"Naim Dali","userId":"15388285116851602609"},"user_tz":-60},"id":"5spi58k9H8Tj"},"outputs":[],"source":["# Generate the new dataset from files and classification.csv\n","\n","def extract_publication(file_list, subdir):\n","    dates = []\n","    captions = []\n","    medias = []\n","    likes = []\n","    comments = []\n","\n","    for file_name in file_list:\n","        # Date\n","        date = datetime.datetime(int(file_name[0:4]), int(file_name[5:7]), int(file_name[8:10]),\n","                                 int(file_name[11:13]), int(file_name[14:16]), int(file_name[17:19]))\n","        date = date.strftime('%Y-%m-%d %H:%M:%S')\n","        dates.append(date)\n","\n","        # Caption\n","        file_path = os.path.join(subdir, file_name)\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            caption = file.read()\n","            captions.append(caption)\n","\n","        # Comments and likes\n","        json_file_path = os.path.join(subdir, file_name)[:-3] + \"json.xz\"\n","\n","        with lzma.open(json_file_path, 'rb') as f:\n","            data = json.loads(f.read().decode())\n","        like = data['node']['edge_media_preview_like']['count']\n","        comment = data['node']['edge_media_to_comment']['count']\n","        likes.append(like)\n","        comments.append(comment)\n","\n","        # Get images\n","        media = str(subdir) + '/' + file_name[:-3] + \"jpg\"\n","        if not os.path.exists(media):\n","            media = str(subdir) + '/' + file_name[:-4] + \"_1.jpg\"\n","\n","        medias.append(media)\n","\n","    return dates, captions, medias, likes, comments\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1685486518410,"user":{"displayName":"Naim Dali","userId":"15388285116851602609"},"user_tz":-60},"id":"QCnmhtFGH118"},"outputs":[],"source":["def generate_dataset_from_data():\n","    users = []\n","    dataset=[]\n","\n","    for subdir, dirs, files in os.walk(root_dir):\n","        user_name=subdir[40:]\n","        dates=[]\n","        captions=[]\n","        medias=[]\n","        likes=[]\n","        comments=[]\n","        file_list = [file for file in files if file.endswith('.txt')] \n","        dates, captions, medias, likes, comments=extract_publication(file_list,subdir)\n","        if len(medias) != 0 and len(captions) != 0 : \n","            dataset.append([user_name,dates, captions, medias, likes, comments])\n","        print([user_name,dates, captions, medias, likes, comments])\n","    print('dataset', dataset)\n","    \n","    \n","    with open('/content/drive/MyDrive/PFA/DATASET/new_dataset.csv', 'w', newline='',encoding='utf-8') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['user_name', 'Dates', 'Captions', 'Medias', 'Likes' , 'Comments'])\n","        for row in dataset:\n","            writer.writerow(row) "]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1685486521419,"user":{"displayName":"Naim Dali","userId":"15388285116851602609"},"user_tz":-60},"id":"mYy70r9K9csB"},"outputs":[],"source":["def merge_datasets():\n","    # load the new_dataset and the classification_dataset\n","    new_dataset = pd.read_csv('/content/drive/MyDrive/PFA/DATASET/new_dataset.csv')\n","    classification_dataset = pd.read_csv('/content/drive/MyDrive/PFA/DATASET/classification_dataset.csv')\n","\n","    # Edit usernames ending with ***\n","    for i in range(0,classification_dataset['user_name'].size):\n","        classification_dataset['user_name'].iloc[i]\n","        if classification_dataset['user_name'].iloc[i].endswith(' ***'):\n","            classification_dataset.loc[i, 'user_name'] = classification_dataset.loc[i, 'user_name'][:-4]\n","            \n","    # Merge the two datasets into final_dataset.csv        \n","    merged_df = pd.merge(new_dataset, classification_dataset, on='user_name')\n","    merged_df=merged_df.drop(columns=['nb_emojis','id','captions'])\n","    merged_df.to_csv('/content/drive/MyDrive/PFA/DATASET/final_dataset.csv')\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EF61mFMi04S-"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5_sKNBnoHgLC"},"outputs":[],"source":["\n","convert_mp4_to_image()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1kAus4mmGbt5wJWRCF3Odc4V9Jfqy3006"},"executionInfo":{"elapsed":202340,"status":"ok","timestamp":1685480784477,"user":{"displayName":"amani bchir","userId":"17875292173569037577"},"user_tz":-60},"id":"mvPw4mXmIx07","outputId":"c9f5cd4d-a0ba-4d0b-e4b8-15318676f41e"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["generate_dataset_from_data()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"69ATRYLeSiGK"},"outputs":[],"source":["merge_datasets()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1kjA60ykYK9f"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}